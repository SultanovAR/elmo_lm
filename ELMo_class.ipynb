{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/sultanov/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/sultanov/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package perluniprops to\n",
      "[nltk_data]     /home/sultanov/nltk_data...\n",
      "[nltk_data]   Package perluniprops is already up-to-date!\n",
      "[nltk_data] Downloading package nonbreaking_prefixes to\n",
      "[nltk_data]     /home/sultanov/nltk_data...\n",
      "[nltk_data]   Package nonbreaking_prefixes is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from deeppavlov.models.bidirectional_lms import elmo_bilm\n",
    "from deeppavlov.models.tokenizers.lazy_tokenizer import LazyTokenizer\n",
    "import kenlm\n",
    "import numpy as np\n",
    "from scipy.stats.mstats import gmean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ELMoAug:\n",
    "    \n",
    "    def __init__(self, \n",
    "                 language: str,\n",
    "                 elmo_path: str,\n",
    "                 kenlm_path: str,\n",
    "                 isalpha_only: bool,\n",
    "                 standard_cases_only: dict,\n",
    "                 ):\n",
    "        self.lang = language\n",
    "        assert self.lang in ['rus', 'eng'], 'It supports only russian and english languages'\n",
    "        self.isalpha_only = isalpha_only\n",
    "        self.standard_cases_only = standard_cases_only\n",
    "        \n",
    "        \n",
    "        \n",
    "        self.elmo = elmo_bilm.ELMoEmbedder(model_dir=\"/cephfs/home/sultanov/elmo_lm/lib/python3.6/site-packages/download/bidirectional_lms/elmo_en_news\")\n",
    "        klm = kenlm.Model('/cephfs/home/sultanov/elmo_lm/lib/python3.6/site-packages/download/ngram_lm/en_wiki_no_punkt.arpa.binary')\n",
    "        self.elmo_vocab_scores = np.array([klm.score(token, bos=False, eos=False) for token in self.elmo.get_vocab()])\n",
    "        self.token2idx = dict(zip(self.elmo.get_vocab(),range(len(self.elmo.get_vocab()))))\n",
    "        \n",
    "    \n",
    "    def _softmax(self, a, axis):\n",
    "        numerator = np.exp(a - np.max(a))\n",
    "        denominator = np.expand_dims(np.sum(numerator, axis=axis), 2)\n",
    "        return numerator / denominator\n",
    "    \n",
    "    \n",
    "    def _unite_distr(self, left_and_right_distr, method):\n",
    "        if method == 'left':\n",
    "            res = left_and_right_distr[:, 0, :]\n",
    "        elif method == 'right':\n",
    "            res = left_and_right_distr[:, 1, :]\n",
    "        elif method == 'max':\n",
    "            res = np.max(left_and_right_distr, axis=1)\n",
    "        elif method == 'min':\n",
    "            res = np.min(left_and_right_distr, axis=1)\n",
    "        elif method == 'both':\n",
    "            res = np.log(left_and_right_distr) # преобразуем в log\n",
    "            res = np.sum(res, axis=1) # суммируем левый и правый контекст\n",
    "            res = res - self.elmo_vocab_scores # вычитаем вероятность отдельных токенов\n",
    "        elif method == 'gmean':\n",
    "            res = gmean(left_and_right_distr, axis=1)\n",
    "        res = self._softmax(res, 1)\n",
    "        return res\n",
    "    \n",
    "    \n",
    "    #def _filter_word(frequence: float, )\n",
    "        \n",
    "    def _get_perplexity(self, corpus, method):\n",
    "        elmo_distr = self.elmo(corpus)\n",
    "        elmo_distr = [self._unite_distr(elmo_distr_sent, method) for elmo_distr_sent in elmo_distr]\n",
    "        idx_corpus = [[self.token2idx.get(token, -1) for token in sentence] for sentence in corpus]\n",
    "        p_perplexity = []\n",
    "        for num_sent, idxs_sent in enumerate(idx_corpus):\n",
    "            for num_token, idx_token in enumerate(idxs_sent):\n",
    "                if idx_token == -1:\n",
    "                    p_perplexity.append(1)\n",
    "                else:\n",
    "                    p_perplexity.append(elmo_distr[num_sent][num_token,idx_token])\n",
    "        perplexity = np.exp(-np.mean(np.log(p_perplexity)))\n",
    "        return perplexity\n",
    "    \n",
    "    \n",
    "    def __call__(self, corpus):\n",
    "        elmo_distr = self.elmo(corpus)\n",
    "        elmo_distr = [self._unite_distr(elmo_distr_sent, 'both') for elmo_distr_sent in elmo_distr]\n",
    "        return elmo_distr\n",
    "                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "alice = nltk.corpus.gutenberg.sents('carroll-alice.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************************************************************************************\n",
      "/cephfs/home/sultanov/elmo_lm/lib/python3.6/site-packages/download/bidirectional_lms/elmo_en_news\n",
      "WARNING:tensorflow:From /cephfs/home/sultanov/elmo_lm/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-01 22:03:19.535 WARNING in 'tensorflow'['deprecation'] at line 323: From /cephfs/home/sultanov/elmo_lm/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /cephfs/home/sultanov/elmo_lm/lib/python3.6/site-packages/bilm/training.py:217: calling squeeze (from tensorflow.python.ops.array_ops) with squeeze_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use the `axis` argument instead\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-01 22:03:19.568 WARNING in 'tensorflow'['deprecation'] at line 506: From /cephfs/home/sultanov/elmo_lm/lib/python3.6/site-packages/bilm/training.py:217: calling squeeze (from tensorflow.python.ops.array_ops) with squeeze_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use the `axis` argument instead\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USING SKIP CONNECTIONS\n",
      "WARNING:tensorflow:From /cephfs/home/sultanov/elmo_lm/lib/python3.6/site-packages/bilm/training.py:372: LSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-01 22:03:19.838 WARNING in 'tensorflow'['deprecation'] at line 323: From /cephfs/home/sultanov/elmo_lm/lib/python3.6/site-packages/bilm/training.py:372: LSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /cephfs/home/sultanov/elmo_lm/lib/python3.6/site-packages/bilm/training.py:396: MultiRNNCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.StackedRNNCells, and will be replaced by that in Tensorflow 2.0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-01 22:03:19.840 WARNING in 'tensorflow'['deprecation'] at line 323: From /cephfs/home/sultanov/elmo_lm/lib/python3.6/site-packages/bilm/training.py:396: MultiRNNCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.StackedRNNCells, and will be replaced by that in Tensorflow 2.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /cephfs/home/sultanov/elmo_lm/lib/python3.6/site-packages/bilm/training.py:410: static_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.RNN(cell, unroll=True)`, which is equivalent to this API\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-01 22:03:19.923 WARNING in 'tensorflow'['deprecation'] at line 323: From /cephfs/home/sultanov/elmo_lm/lib/python3.6/site-packages/bilm/training.py:410: static_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.RNN(cell, unroll=True)`, which is equivalent to this API\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /cephfs/home/sultanov/elmo_lm/lib/python3.6/site-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-01 22:03:20.156 WARNING in 'tensorflow'['deprecation'] at line 323: From /cephfs/home/sultanov/elmo_lm/lib/python3.6/site-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /cephfs/home/sultanov/elmo_lm/lib/python3.6/site-packages/download/bidirectional_lms/elmo_en_news/model.ckpt-935588\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-01 22:03:20.158 INFO in 'tensorflow'['saver'] at line 1270: Restoring parameters from /cephfs/home/sultanov/elmo_lm/lib/python3.6/site-packages/download/bidirectional_lms/elmo_en_news/model.ckpt-935588\n"
     ]
    }
   ],
   "source": [
    "el = ELMoAug('eng', 'hz', 'e', 'e', 'e')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sentences = \\\n",
    "[\"Almost half of all iPhone owners have broken their screens, not just once but an average of two times each.\",\\\n",
    "   \"i really don't understand your point.\\xa0 It seems that you are mixing apples and oranges.\",\\\n",
    "   \"shut the fuck up. you and the rest of your faggot friends should be burned at the stake\",\\\n",
    "   \"That you are an idiot who understands neither taxation nor women's health.\",\\\n",
    "   \"What on Earth is that about? Is it what's going to get him fired eventually?\",\\\n",
    "   \"This is a doctrine of constitutional interpretation that says that a constitution is organic and must be read in a broad and liberal manner so as to adapt it to changing times.\",\\\n",
    "   \"In the 2000s, music notation typically means the written expression of music notes and rhythms on paper using symbols.\",\\\n",
    "   \"Most of the mathematical notation in use today was not invented until the 16th century.[52] Before that, mathematics was written out in words, limiting mathematical discovery.\",\\\n",
    "   \"Physical geography deals with the study of processes and patterns in the natural environment like the atmosphere, hydrosphere, biosphere, and geosphere.\",\\\n",
    "   \"An autobiography is written by the person himself or herself, sometimes with the assistance of a collaborator or ghostwriter.\",\\\n",
    "    \"You fuck your dad.\",\\\n",
    "    \"Yeah and where are you now?\",\\\n",
    "    \"shut the fuck up. you and the rest of your faggot friends should be burned at the stake\",\\\n",
    "    \"you are a land creature. You would drown....\",\\\n",
    "    \"But how would you actually get the key out?\",\\\n",
    "    \"fucking behave then you prick!\",\\\n",
    "    \"You right if you are relaxe then you can give better result or perform and your identity should be from your work.\",\\\n",
    "    \"The laughs you two heard were triggered by memories of his own high-flying exits off moving beasts\",\\\n",
    " \"Well, you guys have gone and done it now. You put the words 'China' and 'Chinese' up the required number of times for the dating Asians ad to come up. Evidently, Ms. Zhang, 50Kg and 168cm [for a BMI of 17.8] from 'HuNan China' wants to meet me. She has her little mouth open like she's speaking. What's that you ask, Zhang? Well, yes, as a matter of fact I am a physician.  Why are you clapping your hands together and jumping up and down?  Stop that squealing, young lady and 'exprain' yourself!\",\\\n",
    " \"Fact : Georgia passed a strict immigration policy and most of the Latino farm workers left the area. Vidalia Georgia now has over 3000 agriculture job openings and they have been able to fill about 250 of them in past year. All you White Real Americans who are looking for work that the Latinos stole from you..Where are you ? The jobs are i Vadalia just waiting for you..Or maybe its the fact that you would rather collect unemployment like the rest of the Tea Klaners.. You scream..you complain..and you sit at home in your wife beaters and drink beer..Typical Real White Tea Klan...\"\n",
    "]\n",
    "test_sentences = list(map(lambda x: x.split(), test_sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['CHAPTER', 'I', '.'],\n",
       " ['Down', 'the', 'Rabbit', '-', 'Hole'],\n",
       " ['Alice',\n",
       "  'was',\n",
       "  'beginning',\n",
       "  'to',\n",
       "  'get',\n",
       "  'very',\n",
       "  'tired',\n",
       "  'of',\n",
       "  'sitting',\n",
       "  'by',\n",
       "  'her',\n",
       "  'sister',\n",
       "  'on',\n",
       "  'the',\n",
       "  'bank',\n",
       "  ',',\n",
       "  'and',\n",
       "  'of',\n",
       "  'having',\n",
       "  'nothing',\n",
       "  'to',\n",
       "  'do',\n",
       "  ':',\n",
       "  'once',\n",
       "  'or',\n",
       "  'twice',\n",
       "  'she',\n",
       "  'had',\n",
       "  'peeped',\n",
       "  'into',\n",
       "  'the',\n",
       "  'book',\n",
       "  'her',\n",
       "  'sister',\n",
       "  'was',\n",
       "  'reading',\n",
       "  ',',\n",
       "  'but',\n",
       "  'it',\n",
       "  'had',\n",
       "  'no',\n",
       "  'pictures',\n",
       "  'or',\n",
       "  'conversations',\n",
       "  'in',\n",
       "  'it',\n",
       "  ',',\n",
       "  \"'\",\n",
       "  'and',\n",
       "  'what',\n",
       "  'is',\n",
       "  'the',\n",
       "  'use',\n",
       "  'of',\n",
       "  'a',\n",
       "  'book',\n",
       "  \",'\",\n",
       "  'thought',\n",
       "  'Alice',\n",
       "  \"'\",\n",
       "  'without',\n",
       "  'pictures',\n",
       "  'or',\n",
       "  'conversation',\n",
       "  \"?'\"],\n",
       " ['So',\n",
       "  'she',\n",
       "  'was',\n",
       "  'considering',\n",
       "  'in',\n",
       "  'her',\n",
       "  'own',\n",
       "  'mind',\n",
       "  '(',\n",
       "  'as',\n",
       "  'well',\n",
       "  'as',\n",
       "  'she',\n",
       "  'could',\n",
       "  ',',\n",
       "  'for',\n",
       "  'the',\n",
       "  'hot',\n",
       "  'day',\n",
       "  'made',\n",
       "  'her',\n",
       "  'feel',\n",
       "  'very',\n",
       "  'sleepy',\n",
       "  'and',\n",
       "  'stupid',\n",
       "  '),',\n",
       "  'whether',\n",
       "  'the',\n",
       "  'pleasure',\n",
       "  'of',\n",
       "  'making',\n",
       "  'a',\n",
       "  'daisy',\n",
       "  '-',\n",
       "  'chain',\n",
       "  'would',\n",
       "  'be',\n",
       "  'worth',\n",
       "  'the',\n",
       "  'trouble',\n",
       "  'of',\n",
       "  'getting',\n",
       "  'up',\n",
       "  'and',\n",
       "  'picking',\n",
       "  'the',\n",
       "  'daisies',\n",
       "  ',',\n",
       "  'when',\n",
       "  'suddenly',\n",
       "  'a',\n",
       "  'White',\n",
       "  'Rabbit',\n",
       "  'with',\n",
       "  'pink',\n",
       "  'eyes',\n",
       "  'ran',\n",
       "  'close',\n",
       "  'by',\n",
       "  'her',\n",
       "  '.']]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alice[1:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['i',\n",
       "  'really',\n",
       "  \"don't\",\n",
       "  'understand',\n",
       "  'your',\n",
       "  'point.',\n",
       "  'It',\n",
       "  'seems',\n",
       "  'that',\n",
       "  'you',\n",
       "  'are',\n",
       "  'mixing',\n",
       "  'apples',\n",
       "  'and',\n",
       "  'oranges.'],\n",
       " ['shut',\n",
       "  'the',\n",
       "  'fuck',\n",
       "  'up.',\n",
       "  'you',\n",
       "  'and',\n",
       "  'the',\n",
       "  'rest',\n",
       "  'of',\n",
       "  'your',\n",
       "  'faggot',\n",
       "  'friends',\n",
       "  'should',\n",
       "  'be',\n",
       "  'burned',\n",
       "  'at',\n",
       "  'the',\n",
       "  'stake'],\n",
       " ['That',\n",
       "  'you',\n",
       "  'are',\n",
       "  'an',\n",
       "  'idiot',\n",
       "  'who',\n",
       "  'understands',\n",
       "  'neither',\n",
       "  'taxation',\n",
       "  'nor',\n",
       "  \"women's\",\n",
       "  'health.'],\n",
       " ['What',\n",
       "  'on',\n",
       "  'Earth',\n",
       "  'is',\n",
       "  'that',\n",
       "  'about?',\n",
       "  'Is',\n",
       "  'it',\n",
       "  \"what's\",\n",
       "  'going',\n",
       "  'to',\n",
       "  'get',\n",
       "  'him',\n",
       "  'fired',\n",
       "  'eventually?']]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sentences[1:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cephfs/home/sultanov/elmo_lm/lib/python3.6/site-packages/ipykernel_launcher.py:25: DeprecationWarning: Both axis > a.ndim and axis < -a.ndim - 1 are deprecated and will raise an AxisError in the future.\n"
     ]
    }
   ],
   "source": [
    "test_result = el(test_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_punkt = np.array([1 if not x in ['</S>','<S>','<UNK>',',','.','\"',')','(','!', '\"', '#', '$', '%', '&', \"'\",] else 0 for x in el.elmo.get_vocab()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "masked_test_result = [dist*mask_punkt for dist in test_result]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cephfs/home/sultanov/elmo_lm/lib/python3.6/site-packages/ipykernel_launcher.py:14: DeprecationWarning: Both axis > a.ndim and axis < -a.ndim - 1 are deprecated and will raise an AxisError in the future.\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "437.9690103768755"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "el._get_perplexity(alice[:500], 'both')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cephfs/home/sultanov/elmo_lm/lib/python3.6/site-packages/ipykernel_launcher.py:14: DeprecationWarning: Both axis > a.ndim and axis < -a.ndim - 1 are deprecated and will raise an AxisError in the future.\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "527405.2165161947"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "el._get_perplexity(alice[:500], 'min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cephfs/home/sultanov/elmo_lm/lib/python3.6/site-packages/ipykernel_launcher.py:14: DeprecationWarning: Both axis > a.ndim and axis < -a.ndim - 1 are deprecated and will raise an AxisError in the future.\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "466731.4349294699"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "el._get_perplexity(alice[:500], 'max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cephfs/home/sultanov/elmo_lm/lib/python3.6/site-packages/ipykernel_launcher.py:14: DeprecationWarning: Both axis > a.ndim and axis < -a.ndim - 1 are deprecated and will raise an AxisError in the future.\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "498326.555375938"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "el._get_perplexity(alice[:500], 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cephfs/home/sultanov/elmo_lm/lib/python3.6/site-packages/ipykernel_launcher.py:14: DeprecationWarning: Both axis > a.ndim and axis < -a.ndim - 1 are deprecated and will raise an AxisError in the future.\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "493966.43769457657"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "el._get_perplexity(alice[:500], 'right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cephfs/home/sultanov/elmo_lm/lib/python3.6/site-packages/ipykernel_launcher.py:14: DeprecationWarning: Both axis > a.ndim and axis < -a.ndim - 1 are deprecated and will raise an AxisError in the future.\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "514554.93212502246"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "el._get_perplexity(alice[:500], 'gmean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _multi_argmax(values: np.ndarray, n_instances: int = 1) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Selects the indices of the n_instances highest values.\n",
    "        Args:\n",
    "            values: Contains the values to be selected from.\n",
    "            n_instances: Specifies how many indices to return.\n",
    "        Returns:\n",
    "            Contains the indices of the n_instances largest values.\n",
    "        \"\"\"\n",
    "        assert n_instances <= values.shape[0], 'n_instances must be less or equal than the size of utility'\n",
    "\n",
    "        max_idx = np.argpartition(-values, n_instances-1, axis=1)[:,:n_instances]\n",
    "        return max_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 10)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = _multi_argmax(values=masked_test_result[0], n_instances=10)\n",
    "idx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 793471)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_result[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Almost', 'half', 'of', 'all', 'iPhone', 'owners', 'have', 'broken', 'their', 'screens,', 'not', 'just', 'once', 'but', 'an', 'average', 'of', 'two', 'times', 'each.']\n"
     ]
    }
   ],
   "source": [
    "sent = test_sentences[0]\n",
    "print(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Almost ['Almost', 'Nearly', 'But', 'Over', 'that', \"'s\", 'About', ':', 'U.S.', 'Around']\n",
      "\n",
      "\n",
      "\n",
      "half ['two-thirds', 'three-quarters', 'one-third', 'half', '1,000', 'three-fourths', 'percent', '2,000', 'all', '3,000']\n",
      "\n",
      "\n",
      "\n",
      "of [':', 'that', 'said', 'U.S.', 'of', 'say', '--', \"'s\", 'the', 'think']\n",
      "\n",
      "\n",
      "\n",
      "all ['those', 'UK', 'that', 'the', \"'s\", ':', 'U.S.', 'all', 'American', 'British']\n",
      "\n",
      "\n",
      "\n",
      "iPhone ['business', 'U.S.', 'home', 'the', \"'s\", 'new', 'phone', 'those', 'iPhone', 'American']\n",
      "\n",
      "\n",
      "\n",
      "owners ['users', 'owners', 'subscribers', 'customers', 'and', \"'s\", 'readers', 'apps', 'consumers', 'buyers']\n",
      "\n",
      "\n",
      "\n",
      "have ['had', \"'s\", \"'ve\", 'have', 'are', '--', 'now', 'who', 'and', 'in']\n",
      "\n",
      "\n",
      "\n",
      "broken ['on', 'at', 'access', 'used', 'use', 'downloaded', 'using', 'to', 'in', 'accessed']\n",
      "\n",
      "\n",
      "\n",
      "their ['the', \"'s\", 'their', 'phone', 'on', 'up', 'off', 'two', 'down', 'U.S.']\n",
      "\n",
      "\n",
      "\n",
      "screens, ['service', '...', '*', ';', 'phone', ':', 'U.S.', 'or', 'hands', \"'s\"]\n",
      "\n",
      "\n",
      "\n",
      "not [';', 'for', 'to', 'of', 'at', ':', 'in', 'and', 'or', 'on']\n",
      "\n",
      "\n",
      "\n",
      "just ['just', 'only', 'least', 'than', 'for', 'used', 'to', 'at', 'using', 'not']\n",
      "\n",
      "\n",
      "\n",
      "once ['on', 'to', ':', 'for', '...', ';', 'in', \"'s\", 'with', 'the']\n",
      "\n",
      "\n",
      "\n",
      "but ['and', 'with', ';', 'or', 'but', 'for', ':', 'to', 'in', 'on']\n",
      "\n",
      "\n",
      "\n",
      "an ['a', 'an', 'twice', \"'s\", 'the', 'more', 'two', 'almost', 'on', 'for']\n",
      "\n",
      "\n",
      "\n",
      "average ['hour', 'estimate', 'additional', 'equivalent', 'amount', 'estimated', 'average', 'increase', 'excess', 'each']\n",
      "\n",
      "\n",
      "\n",
      "of ['of', \"'s\", ':', 'for', 'and', ';', 'or', 'about', 'to', 'over']\n",
      "\n",
      "\n",
      "\n",
      "two ['1.6', '100,000', '1.4', '1.2', '1,000', 'three', 'five', '1.5', '2.5', '1.8']\n",
      "\n",
      "\n",
      "\n",
      "times ['to', 'million', 'times', 'cents', '/', 'per', 'or', 'percent', ';', '...']\n",
      "\n",
      "\n",
      "\n",
      "each. ['of', 'in', 'a', 'at', 'to', 'and', 'before', 'from', ':', ';']\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for num, word in enumerate(idx):\n",
    "    print(sent[num], [el.elmo.get_vocab()[i] for i in word])\n",
    "    print('\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
