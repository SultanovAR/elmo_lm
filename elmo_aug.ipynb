{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/sultanov/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/sultanov/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package perluniprops to\n",
      "[nltk_data]     /home/sultanov/nltk_data...\n",
      "[nltk_data]   Package perluniprops is already up-to-date!\n",
      "[nltk_data] Downloading package nonbreaking_prefixes to\n",
      "[nltk_data]     /home/sultanov/nltk_data...\n",
      "[nltk_data]   Package nonbreaking_prefixes is already up-to-date!\n",
      "/usr/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "from deeppavlov.models.bidirectional_lms import elmo_bilm\n",
    "from deeppavlov.models.tokenizers.lazy_tokenizer import LazyTokenizer\n",
    "from nltk.tokenize.moses import MosesDetokenizer\n",
    "import numpy as np\n",
    "from typing import List\n",
    "from scipy.stats import kurtosis\n",
    "from scipy.stats.mstats import gmean\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ElmoAug:\n",
    "    \n",
    "    def __init__(self, model_dir=\"/cephfs/home/sultanov/elmo_lm/lib/python3.6/site-packages/download/bidirectional_lms/elmo_en_news\"):\n",
    "        self.tokenizer = LazyTokenizer()\n",
    "        self.elmo_lm   = elmo_bilm.ELMoEmbedder(model_dir=model_dir)\n",
    "        self.detokenizer = MosesDetokenizer()\n",
    "        self.tmp_logger = []\n",
    "        self.logger = []\n",
    "        \n",
    "    def _multi_argmax(self, values: np.ndarray, n_instances: int = 1) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Selects the indices of the n_instances highest values.\n",
    "        Args:\n",
    "            values: Contains the values to be selected from.\n",
    "            n_instances: Specifies how many indices to return.\n",
    "        Returns:\n",
    "            Contains the indices of the n_instances largest values.\n",
    "        \"\"\"\n",
    "        assert n_instances <= values.shape[0], 'n_instances must be less or equal than the size of utility'\n",
    "\n",
    "        max_idx = np.argpartition(-values, n_instances-1, axis=0)[:n_instances]\n",
    "        return max_idx\n",
    "    \n",
    "    def _weighted_sum_distr_by_posistion_in_sent(self, distr):\n",
    "        if len(distr) > 4:\n",
    "            weights = np.array([0.2, 0.35] + [0.5]*(len(distr) - 4) + [0.65, 0.8])\n",
    "        else:\n",
    "            weights = 0.5*np.ones(len(distr))\n",
    "        left = distr[:,0,:]\n",
    "        right = distr[:,1,:]\n",
    "        right = right.transpose([1, 0]) * (1-weights)\n",
    "        right = right.transpose([1, 0])\n",
    "        left = left.transpose([1, 0]) * weights\n",
    "        left = left.transpose([1, 0])\n",
    "        return right + left\n",
    "\n",
    "    def _blend_dist(self, batch_distr, num_method):\n",
    "        \"\"\"\n",
    "        blending distr from left and right context\n",
    "        method 0:\n",
    "            sum two distr along left right context\n",
    "        method 1:\n",
    "            weighted sum by place of word in sentence\n",
    "        \"\"\"\n",
    "        if num_method == 0:\n",
    "            return [np.sum(distr, axis=1) for distr in batch_distr]\n",
    "        \n",
    "        elif num_method == 1:\n",
    "            return [self._weighted_sum_distr_by_posistion_in_sent(distr) for distr in batch_distr]\n",
    "        \n",
    "        elif num_method == 2:\n",
    "            return [np.min(distr, axis=1) for distr in batch_distr]\n",
    "        \n",
    "        elif num_method == 3:\n",
    "            return [gmean(distr, axis=1) for distr in batch_distr]\n",
    "    \n",
    "    def _softmax(self, x):\n",
    "        \"\"\"Compute softmax values for each sets of scores in x.\"\"\"\n",
    "        e_x = np.exp(x - np.max(x))\n",
    "        return e_x / e_x.sum()\n",
    "    \n",
    "    def _sample_distr(self, distr):\n",
    "        \"\"\"Sampling from given distribution\"\"\"\n",
    "        threshold = np.random.random_sample()\n",
    "        i = 0\n",
    "        while threshold - distr[i] > 0:\n",
    "            threshold -= distr[i]\n",
    "            i += 1\n",
    "        return i\n",
    "    \n",
    "    def _sent_aug(self, source_sentence, distr, n_top_words, replace_freq: float=1):\n",
    "        result = []\n",
    "        my_true = 0#+\n",
    "        my_sum = 0#+\n",
    "        for i, token in enumerate(source_sentence):\n",
    "            if np.random.rand() < replace_freq:\n",
    "                words = [self.elmo_lm.get_vocab()[index] for index in self._multi_argmax(distr[i], n_top_words)]    \n",
    "                p = self._softmax([distr[i, index] for index in self._multi_argmax(distr[i], n_top_words)])\n",
    "                #result.append(words[self._sample_distr(p)])\n",
    "                word = words[self._sample_distr(p)]#+\n",
    "                result.append(word)#+\n",
    "                if token in words:#1\n",
    "                    my_true += 1#1\n",
    "                    my_sum += 1#1\n",
    "                else:#1\n",
    "                    my_sum += 1#1\n",
    "            else:\n",
    "                result.append(token)\n",
    "        self.tmp_logger.append({'true': my_true, 'sum': my_sum})#+\n",
    "        return result\n",
    "\n",
    "    \n",
    "    def _batch_sent(self, batch_sent: List[str], n_top_words: int, replace_freq: float, num_method_blend: int) -> List[str]:\n",
    "        \"\"\"\n",
    "        Replaces some words in the original sentence with words from the language model with frequency p\n",
    "        Args:\n",
    "            batch_token: Sentences to be augmented \n",
    "            n_top_words: The number of the most likely words from the language model that will be considered as a replacement for the original.\n",
    "            p: frequency of replacing words\n",
    "        Returns:\n",
    "            Contains the augmented sentences\n",
    "        \"\"\"\n",
    "        batch_token    = self.tokenizer(batch_sent)\n",
    "        batch_distr = self._blend_dist(self.elmo_lm(batch_token), num_method_blend)\n",
    "        batch_aug_token = [self._sent_aug(batch_token[i], batch_distr[i], n_top_words, replace_freq) for i in range(len(batch_token))]\n",
    "        self.logger.append({'method': num_method_blend, **pd.DataFrame(self.tmp_logger).sum().to_dict()})\n",
    "        self.tmp_logger = []\n",
    "        return batch_aug_token        \n",
    "    \n",
    "    def __call__(self, batch_sent: List[str], n_top_words: int, replace_freq: float, num_method_blend: int):\n",
    "        batch_aug_token = self._batch_sent(batch_sent, n_top_words, replace_freq, num_method_blend)\n",
    "        return [self.detokenizer.detokenize(i, return_str=True) for i in batch_aug_token]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************************************************************************************\n",
      "/cephfs/home/sultanov/elmo_lm/lib/python3.6/site-packages/download/bidirectional_lms/elmo_en_news\n",
      "WARNING:tensorflow:From /cephfs/home/sultanov/elmo_lm/lib/python3.6/site-packages/bilm/training.py:217: calling squeeze (from tensorflow.python.ops.array_ops) with squeeze_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use the `axis` argument instead\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-10-25 16:39:30.805 WARNING in 'tensorflow'['tf_logging'] at line 125: From /cephfs/home/sultanov/elmo_lm/lib/python3.6/site-packages/bilm/training.py:217: calling squeeze (from tensorflow.python.ops.array_ops) with squeeze_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use the `axis` argument instead\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USING SKIP CONNECTIONS\n",
      "INFO:tensorflow:Restoring parameters from /cephfs/home/sultanov/elmo_lm/lib/python3.6/site-packages/download/bidirectional_lms/elmo_en_news/model.ckpt-935588\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-10-25 16:39:31.393 INFO in 'tensorflow'['tf_logging'] at line 115: Restoring parameters from /cephfs/home/sultanov/elmo_lm/lib/python3.6/site-packages/download/bidirectional_lms/elmo_en_news/model.ckpt-935588\n"
     ]
    }
   ],
   "source": [
    "el = ElmoAug()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sentences = \\\n",
    "[\"Almost half of all iPhone owners have broken their screens, not just once but an average of two times each.\",\\\n",
    "   \"i really don't understand your point.\\xa0 It seems that you are mixing apples and oranges.\",\\\n",
    "   \"shut the fuck up. you and the rest of your faggot friends should be burned at the stake\",\\\n",
    "   \"That you are an idiot who understands neither taxation nor women's health.\",\\\n",
    "   \"What on Earth is that about? Is it what's going to get him fired eventually?\",\\\n",
    "   \"This is a doctrine of constitutional interpretation that says that a constitution is organic and must be read in a broad and liberal manner so as to adapt it to changing times.\",\\\n",
    "   \"In the 2000s, music notation typically means the written expression of music notes and rhythms on paper using symbols.\",\\\n",
    "   \"Most of the mathematical notation in use today was not invented until the 16th century.[52] Before that, mathematics was written out in words, limiting mathematical discovery.\",\\\n",
    "   \"Physical geography deals with the study of processes and patterns in the natural environment like the atmosphere, hydrosphere, biosphere, and geosphere.\",\\\n",
    "   \"An autobiography is written by the person himself or herself, sometimes with the assistance of a collaborator or ghostwriter.\",\\\n",
    "    \"You fuck your dad.\",\\\n",
    "    \"Yeah and where are you now?\",\\\n",
    "    \"shut the fuck up. you and the rest of your faggot friends should be burned at the stake\",\\\n",
    "    \"you are a land creature. You would drown....\",\\\n",
    "    \"But how would you actually get the key out?\",\\\n",
    "    \"fucking behave then you prick!\",\\\n",
    "    \"You right if you are relaxe then you can give better result or perform and your identity should be from your work.\",\\\n",
    "    \"The laughs you two heard were triggered by memories of his own high-flying exits off moving beasts\",\\\n",
    " \"Well, you guys have gone and done it now. You put the words 'China' and 'Chinese' up the required number of times for the dating Asians ad to come up. Evidently, Ms. Zhang, 50Kg and 168cm [for a BMI of 17.8] from 'HuNan China' wants to meet me. She has her little mouth open like she's speaking. What's that you ask, Zhang? Well, yes, as a matter of fact I am a physician.  Why are you clapping your hands together and jumping up and down?  Stop that squealing, young lady and 'exprain' yourself!\",\\\n",
    " \"Fact : Georgia passed a strict immigration policy and most of the Latino farm workers left the area. Vidalia Georgia now has over 3000 agriculture job openings and they have been able to fill about 250 of them in past year. All you White Real Americans who are looking for work that the Latinos stole from you..Where are you ? The jobs are i Vadalia just waiting for you..Or maybe its the fact that you would rather collect unemployment like the rest of the Tea Klaners.. You scream..you complain..and you sit at home in your wife beaters and drink beer..Typical Real White Tea Klan...\"\n",
    "]\n",
    "len(test_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11h 46min 16s, sys: 2h 4min 35s, total: 13h 50min 51s\n",
      "Wall time: 17min 32s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for method in range(4):\n",
    "    el(test_sentences, 7, 1, method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>method</th>\n",
       "      <th>sum</th>\n",
       "      <th>true</th>\n",
       "      <th>acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>545</td>\n",
       "      <td>296</td>\n",
       "      <td>0.543119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>545</td>\n",
       "      <td>309</td>\n",
       "      <td>0.566972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>545</td>\n",
       "      <td>277</td>\n",
       "      <td>0.508257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>545</td>\n",
       "      <td>320</td>\n",
       "      <td>0.587156</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   method  sum  true       acc\n",
       "0       0  545   296  0.543119\n",
       "1       1  545   309  0.566972\n",
       "2       2  545   277  0.508257\n",
       "3       3  545   320  0.587156"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.DataFrame(el.logger)\n",
    "data['acc'] = data['true']/data['sum']\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-10-25 16:57:06.804 DEBUG in 'matplotlib'['__init__'] at line 415: CACHEDIR=/home/sultanov/.cache/matplotlib\n",
      "2018-10-25 16:57:06.806 DEBUG in 'matplotlib.font_manager'['font_manager'] at line 1359: Using fontManager instance from /home/sultanov/.cache/matplotlib/fontlist-v300.json\n",
      "2018-10-25 16:57:06.893 DEBUG in 'matplotlib.pyplot'['pyplot'] at line 211: Loaded backend module://ipykernel.pylab.backend_inline version unknown.\n",
      "2018-10-25 16:57:06.912 DEBUG in 'matplotlib.pyplot'['pyplot'] at line 211: Loaded backend module://ipykernel.pylab.backend_inline version unknown.\n"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cephfs/home/sultanov/elmo_lm/lib/python3.6/site-packages/seaborn/categorical.py:462: FutureWarning: remove_na is deprecated and is a private function. Do not use.\n",
      "  box_data = remove_na(group_data)\n",
      "2018-10-25 16:57:06.974 DEBUG in 'matplotlib.axes._base'['_base'] at line 2491: update_title_pos\n",
      "2018-10-25 16:57:06.988 DEBUG in 'matplotlib.font_manager'['font_manager'] at line 1251: findfont: Matching :family=sans-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=10.0 to DejaVu Sans ('/cephfs/home/sultanov/elmo_lm/lib/python3.6/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf') with score of 0.050000.\n",
      "2018-10-25 16:57:07.119 DEBUG in 'matplotlib.axes._base'['_base'] at line 2491: update_title_pos\n",
      "2018-10-25 16:57:07.141 DEBUG in 'matplotlib.axes._base'['_base'] at line 2491: update_title_pos\n",
      "2018-10-25 16:57:07.257 DEBUG in 'matplotlib.axes._base'['_base'] at line 2491: update_title_pos\n",
      "2018-10-25 16:57:07.285 DEBUG in 'matplotlib.axes._base'['_base'] at line 2491: update_title_pos\n",
      "2018-10-25 16:57:07.303 DEBUG in 'matplotlib.axes._base'['_base'] at line 2491: update_title_pos\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1224x648 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(17,9))\n",
    "sns.boxplot(x='acc', y='method', data=data, orient='h')\n",
    "plt.savefig('./A_min.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from json import JSONEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "j = JSONEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./A_result_exp.json', 'w') as f:\n",
    "    f.write(j.encode(el.logger))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ddd.shape == (batch:3, len_sent:4, left_right:2, vocab_size:5)\n",
    "#left = data[0][:, 0, :]\n",
    "#right = data[0][:, 1, :]\n",
    "#right.shape\n",
    "#\n",
    "#data = [np.array([[[1,1,1,1,1],[5,5,5,5,5]],[[1,1,1,1,1],[5,5,5,5,5]],\\\n",
    "#        [[1,1,1,1,1],[5,5,5,5,5]],[[1,1,1,1,1],[5,5,5,5,5]]]),\\\n",
    "#       np.array([[[1,1,1,1,1],[5,5,5,5,5]],[[1,1,1,1,1],[5,5,5,5,5]],\\\n",
    "#        [[1,1,1,1,1],[5,5,5,5,5]]]),\\\n",
    "#       np.array([[[1,1,1,1,1],[5,5,5,5,5]],[[1,1,1,1,1],[5,5,5,5,5]]])]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
